{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morphology(nn.Module):\n",
    "    '''\n",
    "    Base class for morpholigical operators \n",
    "    For now, only supports stride=1, dilation=1, kernel_size H==W, and padding='same'.\n",
    "    '''\n",
    "    def __init__(self, kernel_size=3, soft_max=True, beta=15, optype=None):\n",
    "        '''\n",
    "        in_channels: scalar\n",
    "        out_channels: scalar, the number of the morphological neure. \n",
    "        kernel_size: scalar, the spatial size of the morphological neure.\n",
    "        soft_max: bool, using the soft max rather the torch.max(), ref: Dense Morphological Networks: An Universal Function Approximator (Mondal et al. (2019)).\n",
    "        beta: scalar, used by soft_max.\n",
    "        type: str, dilation1d or erosion1d.\n",
    "        '''\n",
    "        super(Morphology, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.soft_max = soft_max\n",
    "        self.beta = beta\n",
    "        self.optype = optype\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # self.weight = nn.Parameter(torch.zeros(out_channels, in_channels, kernel_size, kernel_size), requires_grad=True)\n",
    "        # self.weight = nn.Parameter(torch.zeros(batch_size, input_dim, kernel_size), requires_grad=False)\n",
    "        self.weight = nn.Parameter(torch.zeros(1, self.kernel_size[-1], 1), requires_grad=False)\n",
    "        self.unfold = nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)\n",
    "\n",
    "\n",
    "    def fixed_padding(self, inputs):\n",
    "        padded_inputs = F.pad(inputs, (1, 1, 0, 0))\n",
    "        return padded_inputs\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: tensor of shape (B,N,T)\n",
    "        '''\n",
    "        B, N, L = x.shape\n",
    "        # padding\n",
    "        x = self.fixed_padding(x) # (B,N,T) --> (B,N,L), where L is the padding length\n",
    "\n",
    "        x = x.unsqueeze(-2) # (B,N,1,L)\n",
    "        \n",
    "        # # unfold\n",
    "        x = self.unfold(x)  # (B, N*1*kernel_len, L), where L is the numbers of patches  kernel_size = (1, kernel_len)\n",
    "        x = x.reshape(B, N, self.kernel_size[-1], -1) # (B, N, kernel_len, L)\n",
    "\n",
    "        if self.optype == 'erosion1d':\n",
    "            x = self.weight - x # (B, N, kernel_len, L)\n",
    "            # print(self.weight)\n",
    "        elif self.optype == 'dilation1d':\n",
    "            x = self.weight + x # (B, N, kernel_len, L)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        if not self.soft_max:\n",
    "            x, _ = torch.max(x, dim=2, keepdim=False) # (B, N, T)\n",
    "        else:\n",
    "            x = torch.logsumexp(x*self.beta, dim=2, keepdim=False) / self.beta # (B, N, T)\n",
    "\n",
    "        if self.optype == 'erosion1d':\n",
    "            x = -1 * x\n",
    "\n",
    "        # instead of fold, we use view to avoid copy\n",
    "        # x = x.view(-1, self.out_channels, L_sqrt, L_sqrt)  # (B, Cout, L/2, L/2)\n",
    "\n",
    "        return x \n",
    "\n",
    "class Dilation1d(Morphology):\n",
    "    def __init__(self, kernel_size=5, soft_max=True, beta=20):\n",
    "        super(Dilation1d, self).__init__(kernel_size, soft_max, beta, 'dilation1d')\n",
    "\n",
    "class Erosion1d(Morphology):\n",
    "    def __init__(self, kernel_size=5, soft_max=True, beta=20):\n",
    "        super(Erosion1d, self).__init__(kernel_size, soft_max, beta, 'erosion1d')\n",
    "\n",
    "\n",
    "\n",
    "class MorphoEMP1D(nn.Module):\n",
    "    def __init__(self, kernel_size=5, soft_max=True, beta=20, optype=None):\n",
    "        super().__init__()\n",
    "        self.dilation1d = Dilation1d(kernel_size=kernel_size, soft_max=soft_max)\n",
    "        self.erosion1d = Erosion1d(kernel_size=kernel_size, soft_max=soft_max)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xd=self.dilation1d(x)\n",
    "        xe=self.erosion1d(x)\n",
    "        avg = (xd+xe)/2\n",
    "        imf = x - avg\n",
    "        return imf\n",
    "\n",
    "\n",
    "class MCD(nn.Module):\n",
    "    def __init__(self, K_IMP, kernel_size=5, soft_max=True, beta=20, optype=None):\n",
    "        super().__init__()\n",
    "        self.morphoEMP1D = MorphoEMP1D(kernel_size, soft_max=soft_max)\n",
    "        self.K_IMP = K_IMP\n",
    "\n",
    "\n",
    "    def get_next_imf(self, X):\n",
    "        continue_imf = True\n",
    "\n",
    "        while continue_imf:\n",
    "            x1 = self.morphoEMP1D(X)\n",
    "            stop, metric = self.sd_stop(x1, X, sd=0.1)\n",
    "            # print(metric)\n",
    "            if stop:\n",
    "                return x1\n",
    "            else:\n",
    "                X = x1\n",
    "    \n",
    "    def sd_stop(self, proto_imf, prev_imf, sd=0.2, niters=None):\n",
    "        \"\"\"Compute the sd sift stopping metric.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        proto_imf : ndarray\n",
    "            A signal which may be an IMF\n",
    "        prev_imf : ndarray\n",
    "            The previously identified IMF\n",
    "        sd : float\n",
    "            The stopping threshold\n",
    "        niters : int\n",
    "            Number of sift iterations currently completed\n",
    "        niters : int\n",
    "            Number of sift iterations currently completed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            A flag indicating whether to stop siftingg\n",
    "        float\n",
    "            The SD metric value\n",
    "\n",
    "        \"\"\"\n",
    "        metric = torch.sum((proto_imf - prev_imf)**2) / torch.sum(proto_imf**2)\n",
    "\n",
    "        stop = metric < sd\n",
    "\n",
    "        return stop, metric\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        inside_X = X.clone()\n",
    "        continue_sift = True\n",
    "        layer = 0\n",
    "\n",
    "        while continue_sift:\n",
    "            next_imf = self.get_next_imf(inside_X)\n",
    "            next_imf = next_imf.unsqueeze(2)\n",
    "            if layer == 0:\n",
    "                imf = next_imf\n",
    "            else:\n",
    "                imf = torch.cat((imf, next_imf), axis=2)\n",
    "\n",
    "            layer += 1\n",
    "            inside_X = X - imf.sum(2)\n",
    "\n",
    "            if layer == self.K_IMP-1: \n",
    "                imf = torch.cat((imf, inside_X.unsqueeze(2)), axis=2)\n",
    "                continue_sift = False\n",
    "\n",
    "        return imf # (B, N, K, T)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
