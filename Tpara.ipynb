{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "input_len = 96\n",
    "output_len = 72\n",
    "input_dim = 18\n",
    "enc_hidden = 18\n",
    "dec_hidden = 18\n",
    "num_levels = 2\n",
    "dropout = 0.5\n",
    "K_IMP = 6\n",
    "num_heads = 1\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = Dataset_Custom(root_path=root_path, flag='train', size=(input_len, 24, output_len - 24),\n",
    "                               features='M', data_path='Data2.csv', target='Kp', scale=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "model = DPAD_ATT(input_len=input_len, output_len=output_len, input_dim=input_dim,\n",
    "                 enc_hidden=enc_hidden, dec_hidden=dec_hidden, num_levels=num_levels,\n",
    "                 dropout=dropout, K_IMP=K_IMP, num_heads=num_heads)\n",
    "model = model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (seq_x, seq_y) in enumerate(train_loader):\n",
    "        seq_x, seq_y = seq_x.float().cuda(), seq_y.float().cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Batch {i + 1} - Input shape: {seq_x.shape}\")\n",
    "        print(f\"Batch {i + 1} - Target shape: {seq_y.shape}\")\n",
    "\n",
    "        output = model(seq_x)\n",
    "\n",
    "        print(f\"Batch {i + 1} - Output shape: {output.shape}\")\n",
    "\n",
    "        loss = criterion(output, seq_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Batch {i + 1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "\n",
    "print('Training complete')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
